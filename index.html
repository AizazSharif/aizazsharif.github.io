<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Aizaz Sharif </title> <meta name="author" content="Aizaz Sharif"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9C%A8&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://aizazsharif.github.io/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Aizaz</span> Sharif </h1> <p class="desc">AI Expert, Computer Science Major, and a Philomath.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?5116e67a6e57adf0e6bca3aa91f2c29d" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I am Aizaz Sharif, a computer Science Major, AI Engineer, and Researcher in Oslo, Norway. As a Machine Learning Engineer at AI Dev Lab, I build end-to-end LLM architectures while previously researching autonomous driving systems at the VIAS department of Simula Research Laboratory and the University of Oslo.</p> <p>You can download my resume from here: <a href="assets/pdf/Aizaz_CV_General.pdf">Aizaz Sharif Resume</a></p> <h3 id="what-im-building-now">What I’m Building Now</h3> <p>At AI Dev Lab, I’m implementing a production-ready LLM-powered platform (app.saleskik.ai) for processing daily meeting recordings. This involves:</p> <ul> <li>Developing custom RAG solutions using LangChain, LangGraph, and Pinecone</li> <li>Building robust backend infrastructure with Python, Firebase, and Google Cloud services</li> <li>Creating intelligent conversation processing pipelines for context-aware meeting summarization</li> <li>Managing the full ML/LLM development lifecycle from prototyping to production</li> </ul> <h3 id="scientific-contributions">Scientific Contributions</h3> <p>My doctoral research (<a href="https://www.instagram.com/p/DAiWl7gsxuZ/" rel="external nofollow noopener" target="_blank">defended</a> on September 2024) focused on “Testing the Safety and Robustness of Autonomous Cars in a Multi-agent Environment,” where I made three novel scientific contributions:</p> <ul> <li>Adversarial reinforcement learning techniques for testing and improving autonomous systems</li> <li>Systematic benchmarking methodologies for multi-agent RL driving policies</li> <li>Reward modeling frameworks for finding uncertain state space without adversarial training approach</li> </ul> <p>I’ve created and open-sourced <a href="https://github.com/T3AS" rel="external nofollow noopener" target="_blank">platforms</a> for testing multi-agent autonomous driving systems, gaining extensive experience with simulated driving environments and reinforcement learning.</p> <p>Beyond autonomous driving, I have also performed <a href="https://scholar.google.com/citations?user=luceUvgAAAAJ&amp;hl" rel="external nofollow noopener" target="_blank">research</a> in medical imaging, Android security, and software engineering which resulted in multiple publications, including two conference papers and a journal article. This diverse research background has strengthened my ability to apply machine learning techniques across various domains.</p> <h3 id="project-ownership--team-leadership">Project Ownership &amp; Team Leadership</h3> <p>I’ve successfully led teams and managed complex technical projects throughout my career:</p> <ul> <li>At Simula, I independently managed my entire research portfolio, from literature review to conceptualizing novel ideas, executing experiments, analyzing results, and writing papers - all while working autonomously to deliver high-quality scientific contributions</li> <li>At NCCS, I led a team developing a ‘Mobile Phone Digital Forensics’ toolkit, overseeing the entire project lifecycle from concept to beta testing with authorities</li> <li>At AI Dev LAb, I managed end-to-end ML/LLM development workflows and coordinated with cross-functional teams to deliver production-ready AI solutions. I also collaborated directly with clients to understand business requirements and translate them into technical solutions</li> </ul> <h3 id="life-outside-code">Life Outside Code</h3> <p>Outside of my professional life, I enjoy <a href="https://www.instagram.com/aizaz_sharif/" rel="external nofollow noopener" target="_blank">photography</a> and staying active through cycling, table tennis, and squash. I’m an enthusiastic <a href="https://x.com/AizazSharif420/status/1900526252827582512" rel="external nofollow noopener" target="_blank">Tekken player</a> trying to compete at a higher <a href="https://challonge.com/zedxedan/standings" rel="external nofollow noopener" target="_blank">level</a>, and occasionally play other games like Rainbow Six Siege when time allows. I have a curiosity for learning about different cultures and collecting random facts. Living in Norway, I’m exploring the country’s <a href="https://www.instagram.com/p/CNKWqJVJQxK/" rel="external nofollow noopener" target="_blank">beautiful landscapes</a> and diverse regions, as well as engaging in <a href="https://www.instagram.com/p/B5Tigp6Jqw5/" rel="external nofollow noopener" target="_blank">travel photography</a> during my adventures.</p> <h3 id="contact">Contact</h3> <p>For collaboration, future opportunities, or any queries regarding my current or past work, you can reach out using my <strong>email:</strong> aizazsharif@gmail.com and <a href="https://www.linkedin.com/in/aizazsharif/" rel="external nofollow noopener" target="_blank">LinkedIn</a>.</p> <hr> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Apr 23, 2025</th> <td> Moved to a new website theme. Now completing unfinished blogs (both technical and memoirs). </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 27, 2024</th> <td> Defended my PhD thesis </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 11, 2023</th> <td> Blessed with a baby boy! </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/ReMAV_3_page-0001.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ReMAV_3_page-0001.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10043282" class="col-sm-8"> <div class="title">ReMAV: Reward Modeling of Autonomous Vehicles for Finding Likely Failure Events</div> <div class="author"> <em>Aizaz Sharif</em> and Dusica Marijan </div> <div class="periodical"> <em>In IEEE Open Journal of Intelligent Transportation Systems (OJ-ITS)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/OJITS.2024.3479098" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10714436" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/T3AS/ReMAV" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Architecture.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Architecture.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10043283" class="col-sm-8"> <div class="title">Adversarial Deep Reinforcement Learning for Improving the Robustness of Multi-agent Autonomous Driving Policies</div> <div class="author"> <em>Aizaz Sharif</em> and Dusica Marijan </div> <div class="periodical"> <em>In 2022 29th Asia-Pacific Software Engineering Conference (APSEC)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/APSEC57359.2022.00018" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://arxiv.org/pdf/2112.11937.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/T3AS/MAD-ARL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://aizazsharif.github.io/MAD-ARL/" class="btn btn-sm z-depth-0" role="button">Website</a> </div> <div class="abstract hidden"> <p>Autonomous cars are well known for being vulnerable to adversarial attacks that can compromise the safety of the car and pose danger to other road users. To effectively defend against adversaries, it is required to not only test autonomous cars for finding driving errors but to improve the robustness of the cars to these errors. To this end, in this paper, we propose a two-step methodology for autonomous cars that consists of (i) finding failure states in autonomous cars by training the adversarial driving agent, and (ii) improving the robustness of autonomous cars by retraining them with effective adversarial inputs. Our methodology supports testing autonomous cars in a multi-agent environment, where we train and compare adversarial car policy on two custom reward functions to test the driving control decision of autonomous cars. We run experiments in a vision-based high-fidelity urban driving simulated environment. Our results show that adversarial testing can be used for finding erroneous autonomous driving behavior, followed by adversarial training for improving the robustness of deep reinforcement learning-based autonomous driving policies. We demonstrate that the autonomous cars retrained using the effective adversarial inputs noticeably increase the performance of their driving policies in terms of reduced collision and offroad steering errors.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Architecture2.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Architecture2.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10062456" class="col-sm-8"> <div class="title">Evaluating the Robustness of Deep Reinforcement Learning for Autonomous Policies in a Multi-Agent Urban Driving Environment</div> <div class="author"> <em>Aizaz Sharif</em> and Dusica Marijan </div> <div class="periodical"> <em>In 2022 IEEE 22nd International Conference on Software Quality, Reliability and Security (QRS)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/QRS57517.2022.00084" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://arxiv.org/pdf/2112.11947.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/T3AS/Benchmarking-QRS-2022" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Background: Deep reinforcement learning is actively used for training autonomous car policies in a simulated driving environment. Due to the large availability of various reinforcement learning algorithms and the lack of their systematic comparison across different driving scenarios, we are unsure of which ones are more effective for training autonomous car software in single-agent as well as multi-agent driving environments. Aims: A benchmarking framework for the comparison of deep reinforcement learning in a vision-based autonomous driving will open up the possibilities for training better autonomous car driving policies. Method: To address these challenges, we provide an open and reusable benchmarking framework for systematic evaluation and comparative analysis of deep reinforcement learning algorithms for autonomous driving in a single- and multi-agent environment. Using the framework, we perform a comparative study of four discrete and two continuous action space deep reinforcement learning algorithms. We also propose a comprehensive multi-objective reward function designed for the evaluation of deep reinforcement learning-based autonomous driving agents. We run the experiments in a vision-only high-fidelity urban driving simulated environments. Results: The results indicate that only some of the deep reinforcement learning algorithms perform consistently better across single and multi-agent scenarios when trained in various multi-agent-only environment settings. For example, A3C- and TD3-based autonomous cars perform comparatively better in terms of more robust actions and minimal driving errors in both single and multi-agent scenarios. Conclusions: We conclude that different deep reinforcement learning algorithms exhibit different driving and testing performance in different scenarios, which underlines the need for their systematic comparative analysis. The benchmarking framework proposed in this paper facilitates such a comparison.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%61%69%7A%61%7A%73%68%61%72%69%66@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://facebook.com/AizazSharif" title="Facebook" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-facebook"></i></a> <a href="https://github.com/AizazSharif" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://instagram.com/aizaz_sharif" title="Instagram" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-instagram"></i></a> <a href="https://www.linkedin.com/in/aizazsharif" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> <a href="https://scholar.google.com/citations?user=luceUvgAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://twitter.com/AizazSharif420" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note">The best way to reach me out is by email. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Aizaz Sharif. Last updated: April 24, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>